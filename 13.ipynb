{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx2Lx-CmZF0v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.ensemble import VotingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importar datos\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# Lee el archivo Excel en un DataFrame de pandas\n",
        "datos = pd.read_excel(file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "jzQ1YXYWZOEE",
        "outputId": "8dc81de3-ae61-4c65-d0cb-d762fea69c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-62969e90-fe28-4562-9a60-9fedf8bf6b2c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-62969e90-fe28-4562-9a60-9fedf8bf6b2c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Datos_iefic.xlsx to Datos_iefic.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logit = LogisticRegression(solver='lbfgs')\n",
        "xgb = XGBClassifier(objective='binary:logistic')\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='logistic')"
      ],
      "metadata": {
        "id": "s1aE9Pefaphf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Definición de la variable dependiente e independeientes\n",
        "x13 = datos.drop(\"impago\", axis=1)\n",
        "y13 = datos[\"impago\"]"
      ],
      "metadata": {
        "id": "y9WFrHidaswl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rebalanceo\n",
        "#95% -> 0 / 5% -> 1 | 65%-35%\n",
        "# Se hace un oversampling para balancear la muestra\n",
        "#Oversampling a los 1 (Fail) para alcanzar un 35%\n",
        "oversampler = RandomOverSampler(sampling_strategy=0.35, random_state=42)\n",
        "X_resampled, y_resampled = oversampler.fit_resample(x13, y13)\n",
        "\n",
        "#Undersampling a los 0 (Current) para alcanzar un 65%\n",
        "undersampler = RandomUnderSampler(sampling_strategy=0.65, random_state=42)\n",
        "X_resampled, y_resampled = undersampler.fit_resample(X_resampled, y_resampled)"
      ],
      "metadata": {
        "id": "zuWAXmzpawU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------- Red neuronal multicapa --------------------"
      ],
      "metadata": {
        "id": "vJgkNjs-a3I8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar una red neuronal MLP\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='logistic', max_iter=1000, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred_mlp1 = mlp.predict(X_test)\n",
        "\n",
        "# Imprimir un informe de clasificación\n",
        "report = classification_report(y_test, y_pred_mlp1)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFQqEZHBa1lb",
        "outputId": "0f085e9d-b556-4355-a58b-df08fc23176b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.97      0.78      6401\n",
            "           1       0.82      0.22      0.35      4191\n",
            "\n",
            "    accuracy                           0.67     10592\n",
            "   macro avg       0.74      0.60      0.57     10592\n",
            "weighted avg       0.72      0.67      0.61     10592\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------XGB-----------------------------"
      ],
      "metadata": {
        "id": "kcSNewW7bTtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Búsqueda de hiperparámetros\n",
        "param_dist = {\n",
        "    'n_estimators': randint(100, 500),\n",
        "    'max_depth': randint(3, 7),\n",
        "    'learning_rate': uniform(0.01, 0.2),\n",
        "    'subsample': uniform(0.6, 0.3),\n",
        "    'colsample_bytree': uniform(0.6, 0.3)\n",
        "}\n",
        "\n",
        "# Crear un objeto XGBoost para clasificación binaria\n",
        "xgb_model = XGBClassifier(objective='binary:logistic')\n",
        "\n",
        "# Realizar la búsqueda aleatoria de hiperparámetros con menos iteraciones\n",
        "random_search = RandomizedSearchCV(xgb_model, param_distributions=param_dist, n_iter=20, cv=5, scoring='precision', n_jobs=-1, verbose=1, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Obtener los mejores hiperparámetros\n",
        "best_params = random_search.best_params_\n",
        "\n",
        "# Utilizar el modelo xgb_model con los mejores hiperparámetros\n",
        "xgb_model.set_params(**best_params)\n",
        "\n",
        "# Entrenar el modelo XGBoost con los mejores hiperparámetros\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en tus datos de prueba\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvHyLhBCcir9",
        "outputId": "57a23a9c-edc3-417c-be2d-4194fb23d9cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8U1sWKKjj2u",
        "outputId": "8cdf2f76-5bb6-436f-c954-470eabec2aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'colsample_bytree': 0.8313811040057837, 'learning_rate': 0.024808930346818074, 'max_depth': 5, 'n_estimators': 140, 'subsample': 0.8744879026631343}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from scipy.stats import randint, uniform\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Nuevos valores de hiperparámetros\n",
        "new_params = {\n",
        "    'n_estimators': 80,\n",
        "    'max_depth': 2,\n",
        "    'learning_rate': 0.01,\n",
        "    'subsample': 0.6,\n",
        "    'colsample_bytree': 0.6\n",
        "}\n",
        "\n",
        "# Actualizar el modelo XGBoost con los nuevos hiperparámetros\n",
        "xgb_model.set_params(**new_params)\n",
        "\n",
        "# Entrenar el modelo XGBoost con los nuevos hiperparámetros\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en tus datos de prueba\n",
        "y_pred1 = xgb_model.predict(X_test)\n",
        "\n",
        "# Calcular métricas\n",
        "accuracy = accuracy_score(y_test, y_pred1)\n",
        "precision = precision_score(y_test, y_pred1)\n",
        "recall = recall_score(y_test, y_pred1)\n",
        "f1 = f1_score(y_test, y_pred1)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-Score: {f1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNXmfrZfhfpQ",
        "outputId": "0e965564-2ec1-494e-ed3a-2c4ac95a8b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9336291540785498\n",
            "Precision: 1.0\n",
            "Recall: 0.8322596039131472\n",
            "F1-Score: 0.9084516213048575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------- Random Forest -----------------------"
      ],
      "metadata": {
        "id": "hXHsXih9kS_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "#Entrenar modelo\n",
        "rf.fit(X_train, y_train)\n",
        "#Calibrar hiperparametros\n",
        "# Definir la cuadrícula de hiperparámetros a buscar\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 120 ,150, 200],\n",
        "    'max_depth': [5, 10, 25, 50],\n",
        "}\n",
        "\n",
        "# Crear el objeto GridSearchCV\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Realizar la búsqueda de hiperparámetros\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Obtener los mejores hiperparámetros\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "print(best_params)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Calcular las métricas\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-Score: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVw7M_B2j46I",
        "outputId": "026eab44-a982-484d-9134-c5286fc2d6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 25, 'n_estimators': 120}\n",
            "Accuracy: 0.9948074018126888\n",
            "Precision: 0.9930853600381497\n",
            "Recall: 0.9937962300167025\n",
            "F1-Score: 0.9934406678592725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------- Logit -----------------"
      ],
      "metadata": {
        "id": "U-THjtEanSCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir hiperparámetros a calibrar\n",
        "logit_params = {'C': [0.1, 1, 5,10, 100]}\n",
        "\n",
        "# Crear un modelo de regresión logística\n",
        "logit = LogisticRegression()\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear una instancia de StratifiedKFold para la validación cruzada\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Realizar la búsqueda de hiperparámetros\n",
        "logit_grid = GridSearchCV(logit, logit_params, cv=skf, scoring='accuracy')\n",
        "logit_grid.fit(X_train, y_train)\n",
        "\n",
        "# Imprimir los mejores hiperparámetros\n",
        "print(\"Mejores hiperparámetros para Regresión Logística:\", logit_grid.best_params_)\n",
        "\n",
        "# Obtener las probabilidades predichas en el conjunto de prueba\n",
        "y_pred_prob = logit_grid.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Definir una lista de umbrales\n",
        "thresholds = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "\n",
        "# Iterar sobre los umbrales y evaluar el rendimiento\n",
        "for threshold in thresholds:\n",
        "    y_pred = (y_pred_prob > threshold).astype(int)\n",
        "\n",
        "    # Calcular métricas de rendimiento\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Umbral: {threshold}, Precisión: {precision}, Recall: {recall}, Exactitud: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LniVIhqAnVEP",
        "outputId": "0ccb9b0e-dd38-40a5-8c96-eb436d15a2c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores hiperparámetros para Regresión Logística: {'C': 0.1}\n",
            "Umbral: 0.2, Precisión: 0.39583135954523924, Recall: 0.9968981150083512, Exactitud: 0.396714501510574\n",
            "Umbral: 0.3, Precisión: 0.3963903743315508, Recall: 0.9904557384872346, Exactitud: 0.399452416918429\n",
            "Umbral: 0.4, Precisión: 0.3948306595365419, Recall: 0.9513242662848962, Exactitud: 0.4037953172205438\n",
            "Umbral: 0.5, Precisión: 0.7322654462242563, Recall: 0.3054163684084944, Exactitud: 0.6809856495468278\n",
            "Umbral: 0.6, Precisión: 0.6398601398601399, Recall: 0.043664996420901936, Exactitud: 0.6118768882175226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------- Modelos de ensamble -----------"
      ],
      "metadata": {
        "id": "OIt4IlvA8D9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voting"
      ],
      "metadata": {
        "id": "3xg7ruH48JAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Dividir tus datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Obtener las predicciones de cada modelo\n",
        "pred_logit = y_pred_prob\n",
        "pred_mlp = y_pred_mlp1\n",
        "pred_xgb = y_pred_xgb\n",
        "\n",
        "# Crear un ensemble de votación\n",
        "voting_model = VotingClassifier(estimators=[\n",
        "    ('logit', pred_logit),\n",
        "    ('mlp', pred_mlp),\n",
        "    ('xgb', pred_xgb)\n",
        "], voting='hard')\n",
        "\n",
        "# Crea una matriz con las predicciones de tus modelos\n",
        "predictions_matrix = np.column_stack((pred_logit, pred_mlp, pred_xgb))\n",
        "\n",
        "y_pred_voting = stats.mode(predictions_matrix, axis=1).mode.ravel()\n"
      ],
      "metadata": {
        "id": "iqsPHy4TnjfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = y_test  # Reemplaza 'y_test' con tus etiquetas reales\n",
        "\n",
        "# Calcular métricas de rendimiento para 'y_pred_voting'\n",
        "accuracy = accuracy_score(y_true, y_pred_voting)\n",
        "precision = precision_score(y_true, y_pred_voting)\n",
        "recall = recall_score(y_true, y_pred_voting)\n",
        "f1 = f1_score(y_true, y_pred_voting)\n",
        "\n",
        "# Imprimir las métricas\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-Score: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kns5k4bj5gVu",
        "outputId": "87f5a744-5677-499d-b9a4-cbbbcdb2ad00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6907099697885196\n",
            "Precision: 0.9956663055254604\n",
            "Recall: 0.2192794082557862\n",
            "F1-Score: 0.35940555338287056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacking"
      ],
      "metadata": {
        "id": "1Uw1z7IS8MB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Stacking\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from scipy import stats\n",
        "\n",
        "# Dividir tus datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. Entrena tus modelos base\n",
        "logit = LogisticRegression(solver='lbfgs')\n",
        "logit.fit(X_train, y_train)\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='logistic', max_iter=1000, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Nuevos valores de hiperparámetros para XGB (como en tu código original)\n",
        "new_params = {\n",
        "    'n_estimators': 80,\n",
        "    'max_depth': 2,\n",
        "    'learning_rate': 0.01,\n",
        "    'subsample': 0.6,\n",
        "    'colsample_bytree': 0.6\n",
        "}\n",
        "\n",
        "xgb_model = XGBClassifier(objective='binary:logistic', **new_params)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# 2. Obtener las predicciones de cada modelo\n",
        "pred_logit = logit.predict(X_test)\n",
        "pred_mlp = mlp.predict(X_test)\n",
        "pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Crear un ensemble con un modelo de votación\n",
        "estimators = [\n",
        "    ('logit', logit),\n",
        "    ('mlp', mlp),\n",
        "    ('xgb', xgb_model)\n",
        "]\n",
        "\n",
        "# Crear un modelo de apilamiento (StackingClassifier) con un modelo meta (en este caso, Logistic Regression)\n",
        "stacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "\n",
        "# Entrenar el modelo de apilamiento en el conjunto de entrenamiento\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones con el modelo de apilamiento en el conjunto de prueba\n",
        "y_pred_stacking = stacking_model.predict(X_test)\n",
        "\n",
        "# Calcular métricas de rendimiento para 'y_pred_stacking'\n",
        "accuracy = accuracy_score(y_test, y_pred_stacking)\n",
        "precision = precision_score(y_test, y_pred_stacking)\n",
        "recall = recall_score(y_test, y_pred_stacking)\n",
        "f1 = f1_score(y_test, y_pred_stacking)\n",
        "\n",
        "# Imprimir las métricas\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-Score: {f1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOSwj8Dg6-yL",
        "outputId": "395db215-4d99-41c8-ed2b-d707cb5a6af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.947129909365559\n",
            "Precision: 0.9913396481732071\n",
            "Recall: 0.8740157480314961\n",
            "F1-Score: 0.9289880801420238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Promedios"
      ],
      "metadata": {
        "id": "nWF104-U9f_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Obtener las predicciones de cada modelo\n",
        "y_pred_logit = logit_grid.predict(X_test)\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Calcular las precisiones de cada modelo\n",
        "accuracy_logit = accuracy_score(y_test, y_pred_logit)\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "\n",
        "# Calcular el promedio de las precisiones\n",
        "average_accuracy = (accuracy_logit + accuracy_mlp + accuracy_xgb) / 4\n",
        "\n",
        "print(f'Accuracy promedio de los modelos: {average_accuracy}')\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Obtener las predicciones de cada modelo\n",
        "y_pred_logit = logit_grid.predict(X_test)\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Crear un arreglo que contenga todas las predicciones\n",
        "all_predictions = [y_pred_logit, y_pred_mlp, y_pred_xgb]\n",
        "\n",
        "# Crear una matriz de confusión combinando las predicciones de todos los modelos\n",
        "combined_predictions = np.mean(all_predictions, axis=0)  # Promedio de las predicciones\n",
        "\n",
        "# Redondear las predicciones combinadas a 0 o 1\n",
        "combined_predictions = np.round(combined_predictions)\n",
        "\n",
        "# Calcular la matriz de confusión para las predicciones combinadas\n",
        "confusion = confusion_matrix(y_test, combined_predictions)\n",
        "\n",
        "# Imprimir la matriz de confusión\n",
        "print(\"Matriz de Confusión Combinada:\")\n",
        "print(confusion)\n",
        "tn = confusion[0, 0] #Verdaderos negativos\n",
        "fn = confusion[1, 0] #falsos negativos\n",
        "fp = confusion[0, 1] #falsos positivos\n",
        "tp = confusion[1, 1] #Verdaderos positivos\n",
        "\n",
        "sensitividad = tp / (tp + fp) #sensitividad\n",
        "print(sensitividad)\n",
        "especificidad = tn / (tn + fn) #especificidad\n",
        "print(especificidad)\n",
        "fal_neg = fn / (fn + tn)\n",
        "print(fal_neg)\n",
        "fal_pos = fp / (fp + tp)\n",
        "print(fal_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2cWUc4H9huH",
        "outputId": "3c67540f-c042-4835-9e59-5608deadefa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy promedio de los modelos: 0.5720118957703928\n",
            "Matriz de Confusión Combinada:\n",
            "[[6231  170]\n",
            " [2861 1330]]\n",
            "0.8866666666666667\n",
            "0.6853277606687197\n",
            "0.31467223933128025\n",
            "0.11333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entrenar y evaluar el modelo XGBoost\n",
        "xgb_model = XGBClassifier()\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Calcular métricas para el modelo XGBoost\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
        "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
        "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
        "\n",
        "# Imprimir métricas para el modelo XGBoost\n",
        "print(\"XGBoost Metrics:\")\n",
        "print(f'Accuracy: {accuracy_xgb}')\n",
        "print(f'Precision: {precision_xgb}')\n",
        "print(f'Recall: {recall_xgb}')\n",
        "print(f'F1-Score: {f1_xgb}')\n",
        "\n",
        "# Entrenar y evaluar el modelo de Regresión Logística\n",
        "logit = LogisticRegression()\n",
        "logit.fit(X_train, y_train)\n",
        "y_pred_logit = logit.predict(X_test)\n",
        "\n",
        "# Calcular métricas para el modelo de Regresión Logística\n",
        "accuracy_logit = accuracy_score(y_test, y_pred_logit)\n",
        "precision_logit = precision_score(y_test, y_pred_logit)\n",
        "recall_logit = recall_score(y_test, y_pred_logit)\n",
        "f1_logit = f1_score(y_test, y_pred_logit)\n",
        "\n",
        "# Imprimir métricas para el modelo de Regresión Logística\n",
        "print(\"Logistic Regression Metrics:\")\n",
        "print(f'Accuracy: {accuracy_logit}')\n",
        "print(f'Precision: {precision_logit}')\n",
        "print(f'Recall: {recall_logit}')\n",
        "print(f'F1-Score: {f1_logit}')\n",
        "\n",
        "# Entrenar y evaluar la Red Neuronal MLP\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='logistic', max_iter=1000, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "# Calcular métricas para la Red Neuronal MLP\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "precision_mlp = precision_score(y_test, y_pred_mlp)\n",
        "recall_mlp = recall_score(y_test, y_pred_mlp)\n",
        "f1_mlp = f1_score(y_test, y_pred_mlp)\n",
        "\n",
        "# Imprimir métricas para la Red Neuronal MLP\n",
        "print(\"MLP Metrics:\")\n",
        "print(f'Accuracy: {accuracy_mlp}')\n",
        "print(f'Precision: {precision_mlp}')\n",
        "print(f'Recall: {recall_mlp}')\n",
        "print(f'F1-Score: {f1_mlp}')\n",
        "\n",
        "# Calcular el promedio de métricas\n",
        "avg_accuracy = (accuracy_xgb + accuracy_logit + accuracy_mlp) / 3\n",
        "avg_precision = (precision_xgb + precision_logit + precision_mlp) / 3\n",
        "avg_recall = (recall_xgb + recall_logit + recall_mlp) / 3\n",
        "avg_f1 = (f1_xgb + f1_logit + f1_mlp) / 3\n",
        "\n",
        "# Imprimir el promedio de métricas\n",
        "print(\"Promedio de Métricas:\")\n",
        "print(f'Accuracy: {avg_accuracy}')\n",
        "print(f'Precision: {avg_precision}')\n",
        "print(f'Recall: {avg_recall}')\n",
        "print(f'F1-Score: {avg_f1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XmvF7Hb_V5J",
        "outputId": "3f4a61c0-08dc-4f87-ac1f-81199d83d912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Metrics:\n",
            "Accuracy: 0.9913141993957704\n",
            "Precision: 0.9944511459589868\n",
            "Recall: 0.9835361488904796\n",
            "F1-Score: 0.9889635316698656\n",
            "Logistic Regression Metrics:\n",
            "Accuracy: 0.6809856495468278\n",
            "Precision: 0.7322654462242563\n",
            "Recall: 0.3054163684084944\n",
            "F1-Score: 0.43104899814783637\n",
            "MLP Metrics:\n",
            "Accuracy: 0.6734327794561934\n",
            "Precision: 0.823321554770318\n",
            "Recall: 0.22238129324743497\n",
            "F1-Score: 0.35017847078715003\n",
            "Promedio de Métricas:\n",
            "Accuracy: 0.7819108761329305\n",
            "Precision: 0.8500127156511871\n",
            "Recall: 0.503777936848803\n",
            "F1-Score: 0.590063666868284\n"
          ]
        }
      ]
    }
  ]
}